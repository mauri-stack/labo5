import numpy as npimport matplotlib.pyplot as pltimport timeimport pandas as pdimport osfrom scipy.signal import find_peaks from scipy.optimize import curve_fitimport scipy.stats as stfrom scipy.optimize import minimizeimport scipy.special as spsfrom scipy.stats import poisson#%%def cargar_datos_2(n, i, ruta, a):        #n número de datos tomados +1    # i número de medición -1 (empezando a contar desde 1)    # sufijo para cada medición distinta    columnas = [f'{j}' for j in range(1, n)]    # Rutas a archivos    señales_Ch1 = os.path.join(ruta, 'Mediciones_CH1.csv')    tiempos_Ch1 = os.path.join(ruta, 'Tiempos_CH1.csv')    unidades_escalas = os.path.join(ruta, 'Unidades y escala.csv')    # Lectura de archivos    data_señales_Ch1 = pd.read_csv(señales_Ch1, skiprows=3, delimiter=',', header=None, names=columnas, usecols=range(1, n))    data_tiempos_Ch1 = pd.read_csv(tiempos_Ch1, skiprows=3, delimiter=',', header=None, names=columnas, usecols=range(1, n))    data_unidades_escalas = pd.read_csv(unidades_escalas, delimiter=',', header=None, names=columnas)    # Selección de columna    col_name = str(i + 1)    # Variables con sufijo personalizado    globals()[f'tiempos1_{a}'] = data_tiempos_Ch1[col_name].values    globals()[f'voltajes1_{a}'] = data_señales_Ch1[col_name].values    escala_Ch1 = float(data_unidades_escalas[col_name].iloc[4])    globals()[f'error_Ch1_{a}'] = escala_Ch1 * 10 / 256def cargar_datos(ruta, n):    """Carga los archivos CSV una sola vez y devuelve DataFrames."""    columnas = [f'{j}' for j in range(1, n)]    data_señales = pd.read_csv(os.path.join(ruta, 'Mediciones_CH1.csv'), skiprows=3, header=None, names=columnas, usecols=range(1, n))    data_tiempos = pd.read_csv(os.path.join(ruta, 'Tiempos_CH1.csv'), skiprows=3, header=None, names=columnas, usecols=range(1, n))    data_unidades = pd.read_csv(os.path.join(ruta, 'Unidades y escala.csv'), header=None, names=columnas, usecols=range(1, n))    return data_señales, data_tiempos, data_unidadesdef mle_lambda_from_data(data):    """    MLE Poisson para datos individuales.    Devuelve lambda_hat y su incertidumbre por teoría asintótica.    """    data = np.asarray(data)    n = len(data)    lam_hat = data.mean()    sigma = np.sqrt(lam_hat / n)   # sqrt(Var(lam_hat))    return lam_hat, sigmadef analisis_rapido(n, ruta, h, dis, pro, i_graficado, x_min, x_max, graficar = True, Poisson = False):    """Analiza todos los canales sin recargar archivos en cada iteración."""        data_señales, data_tiempos, data_unidades = cargar_datos(ruta, n)    escala = data_unidades.iloc[4].astype(float)  # escala por columna    intensidades = []    numero_de_picos = []    for i in range(0, n-1):        col_name = str(i + 1)        # Señal y parámetros        señal = (-1) * data_señales[col_name].values        escala_i = escala[col_name]        error = escala_i * 10 / 256        # Detección de picos        peaks, _ = find_peaks(señal, height=h, distance=dis, prominence=pro)        intensidades.extend(señal[peaks])        numero_de_picos.append(len(peaks))        # Liberar memoria de arrays grandes explícitamente        del señal, peaks    if graficar:                for i in range(10):        # Crear figura con dos subplots (1 fila, 2 columnas)            fig, axs = plt.subplots(1, 1, figsize=(10, 4))  # ancho 10, alto 4                cargar_datos_2(n = n, i = i, ruta = ruta, a = "g")            señal = voltajes1_g * (-1)            peaks, _ = find_peaks(señal, height=h, distance=dis, prominence=pro)                axs.plot(tiempos1_g, señal, label='Señal', color = 'indianred')            axs.plot(tiempos1_g[peaks], señal[peaks], 'ro', label='Picos detectados')            axs.legend()                        #axs[0].set_xlim(x_min, x_max)            axs.axhline(y=h, color="cadetblue", linestyle="--", linewidth=1, label="Label vline")            axs.set_title('Ejemplo medición')            axs.set_xlabel('Tiempo [s]')            axs.set_ylabel('Amplitud [V]')                        # axs[0].plot(tiempos1_g, señal, label='Señal', color = 'indianred')            # axs[0].plot(tiempos1_g[peaks], señal[peaks], 'ro', label='Picos detectados')            # axs[0].legend()                        # #axs[0].set_xlim(x_min, x_max)            # axs[0].axhline(y=h, color="cadetblue", linestyle="--", linewidth=1, label="Label vline")            # axs[0].set_title('Ejemplo medición')            # axs[0].set_xlabel('Tiempo [s]')            # axs[0].set_ylabel('Amplitud [V]')                # --- Histograma 1: intensidades ---            # axs[1].hist(intensidades, density=True, bins=30, histtype='barstacked', alpha=0.7, color='teal', edgecolor='gray')            # axs[1].set_xlabel('Intensidad del pico')            # axs[1].set_ylabel('Frecuencia')            # axs[1].set_yscale('log')            # axs[1].set_title('Distribución de intensidades')                    # Ajustar espacios entre gráficos            plt.tight_layout()            plt.show()    if Poisson:            fig, axs = plt.subplots(1, 1, figsize=(6, 3))                # --- (1,0) Histograma de cantidad de picos ---        numero_de_picos = np.array(numero_de_picos)                #numero_de_picos=numero_de_picos[numero_de_picos<20]                bins = np.arange(numero_de_picos.min(), numero_de_picos.max() + 2)                axs.hist(numero_de_picos, density=True, bins=bins,                color='darkcyan', edgecolor='slateblue', align='left')        #axs.set_title('Cantidad de picos por medición')        axs.set_xlabel('Cantidad de picos')        #axs.set_xlim(0,15)        axs.set_ylabel('Frecuencia')            mean=np.mean(numero_de_picos)        std=np.std(numero_de_picos)                print("Media:", mean)        print("Varianza:", std**2)        print("Var teórica B-E:", mean**2 + mean)        # Ajustar distribución de subplots        plt.tight_layout()        plt.show()            return numero_de_picos#%%Histograma y Ajustenumero_de_picos = analisis_rapido(n = 1001, ruta ='/Users/Mauri/Desktop/Labo 5/Conteo de fotones/theta = 180',          h = 0.002, dis = 7, pro = 0, i_graficado = 7, x_min = -4e-5, x_max = 4e-5,         graficar = False, Poisson = True)#%%Histogramafig, axs = plt.subplots(1, 1, figsize=(6, 3))numero_de_picos=numero_de_picos[numero_de_picos<20]bins = np.arange(numero_de_picos.min(), numero_de_picos.max() + 2)#calculamos los errores de los binscounts, bin_edges = np.histogram(numero_de_picos, bins=bins)#Centros del bin y erroresbin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:]) -0.5bin_err = np.sqrt(counts)#como graficamos la densidad de probabilidad (va, es discreta pero se entiende), los normalizamosdensity_counts = counts / (np.sum(counts) * np.diff(bin_edges))errors_density = bin_err / (np.sum(counts) * np.diff(bin_edges))#Graficar conteos en cada bin con barras de erroraxs.errorbar(bin_centers, density_counts, yerr=errors_density,             fmt='o', color='black', capsize=4, markersize=4)axs.hist(numero_de_picos, density=True, bins=bins,        color='darkcyan', edgecolor='slateblue', align='left')axs.set_xlabel('Cantidad de picos')axs.set_ylabel('Frecuencia')mean=np.mean(numero_de_picos)std=np.std(numero_de_picos)vals = numero_de_picos#Esto caclula lambda con el MLElam, lam_err = mle_lambda_from_data(numero_de_picos)print(f"λ ={lam:.2f} ± {lam_err:.2f}")# --- Curva de Poisson "continua" ---k_fine = np.linspace(vals.min(), vals.max(), 500)pmf_fine = poisson.pmf(np.round(k_fine), lam)axs.plot(k_fine, pmf_fine, 'r-', linewidth=2, label=f"λ ={lam:.2f} ± {lam_err:.2f}")print("Media:", mean)print("Varianza:", std**2)#print("Var teórica B-E:", mean**2 + mean)axs.legend()plt.tight_layout()plt.show()#%%