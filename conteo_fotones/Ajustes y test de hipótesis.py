import numpy as npimport matplotlib.pyplot as pltimport timeimport pandas as pdimport osfrom scipy.signal import find_peaks from scipy.optimize import curve_fitimport scipy.stats as stfrom scipy.optimize import minimizeimport scipy.special as spsfrom scipy.stats import poissonfrom scipy.stats import geom # Esta es la Bose-Einstein (creo)#%%def cargar_datos_2(n, i, ruta, a):        #n número de datos tomados +1    # i número de medición -1 (empezando a contar desde 1)    # sufijo para cada medición distinta    columnas = [f'{j}' for j in range(1, n)]    # Rutas a archivos    señales_Ch1 = os.path.join(ruta, 'Mediciones_CH1.csv')    tiempos_Ch1 = os.path.join(ruta, 'Tiempos_CH1.csv')    unidades_escalas = os.path.join(ruta, 'Unidades y escala.csv')    # Lectura de archivos    data_señales_Ch1 = pd.read_csv(señales_Ch1, skiprows=3, delimiter=',', header=None, names=columnas, usecols=range(1, n))    data_tiempos_Ch1 = pd.read_csv(tiempos_Ch1, skiprows=3, delimiter=',', header=None, names=columnas, usecols=range(1, n))    data_unidades_escalas = pd.read_csv(unidades_escalas, delimiter=',', header=None, names=columnas)    # Selección de columna    col_name = str(i + 1)    # Variables con sufijo personalizado    globals()[f'tiempos1_{a}'] = data_tiempos_Ch1[col_name].values    globals()[f'voltajes1_{a}'] = data_señales_Ch1[col_name].values    escala_Ch1 = float(data_unidades_escalas[col_name].iloc[4])    globals()[f'error_Ch1_{a}'] = escala_Ch1 * 10 / 256def cargar_datos(ruta, n):    """Carga los archivos CSV una sola vez y devuelve DataFrames."""    columnas = [f'{j}' for j in range(1, n)]    data_señales = pd.read_csv(os.path.join(ruta, 'Mediciones_CH1.csv'), skiprows=3, header=None, names=columnas, usecols=range(1, n))    data_tiempos = pd.read_csv(os.path.join(ruta, 'Tiempos_CH1.csv'), skiprows=3, header=None, names=columnas, usecols=range(1, n))    data_unidades = pd.read_csv(os.path.join(ruta, 'Unidades y escala.csv'), header=None, names=columnas, usecols=range(1, n))    return data_señales, data_tiempos, data_unidadesdef mle_lambda_from_data(data):    """    MLE Poisson para datos individuales.    Devuelve lambda_hat y su incertidumbre por teoría asintótica.    """    data = np.asarray(data)    n = len(data)    lam_hat = data.mean()    sigma = np.sqrt(lam_hat / n)   # sqrt(Var(lam_hat))    return lam_hat, sigmadef analisis_rapido(n, ruta, h, dis, pro, i_graficado,m_max, graficar = True, Poisson = False):    """Analiza todos los canales sin recargar archivos en cada iteración."""        data_señales, data_tiempos, data_unidades = cargar_datos(ruta, n)    escala = data_unidades.iloc[4].astype(float)  # escala por columna    intensidades = []    numero_de_picos = []    for i in range(0, n-1):        col_name = str(i + 1)        # Señal y parámetros        señal = (-1) * data_señales[col_name].values        escala_i = escala[col_name]        error = escala_i * 10 / 256        # Detección de picos        peaks, _ = find_peaks(señal, height=h, distance=dis, prominence=pro)        intensidades.extend(señal[peaks])        numero_de_picos.append(len(peaks))        # Liberar memoria de arrays grandes explícitamente        del señal, peaks    if graficar:                for i in range(10):        # Crear figura con dos subplots (1 fila, 2 columnas)            fig, axs = plt.subplots(1, 1, figsize=(10, 4))  # ancho 10, alto 4                cargar_datos_2(n = n, i = i, ruta = ruta, a = "g")            señal = voltajes1_g * (-1)            peaks, _ = find_peaks(señal, height=h, distance=dis, prominence=pro)                axs.plot(tiempos1_g, señal, label='Señal', color = 'indianred')            axs.plot(tiempos1_g[peaks], señal[peaks], 'ro', label='Picos detectados')            axs.legend()                        #axs[0].set_xlim(x_min, x_max)            axs.axhline(y=h, color="cadetblue", linestyle="--", linewidth=1, label="Label vline")            axs.set_title('Ejemplo medición')            axs.set_xlabel('Tiempo [s]')            axs.set_ylabel('Amplitud [V]')                        # axs[0].plot(tiempos1_g, señal, label='Señal', color = 'indianred')            # axs[0].plot(tiempos1_g[peaks], señal[peaks], 'ro', label='Picos detectados')            # axs[0].legend()                        # #axs[0].set_xlim(x_min, x_max)            # axs[0].axhline(y=h, color="cadetblue", linestyle="--", linewidth=1, label="Label vline")            # axs[0].set_title('Ejemplo medición')            # axs[0].set_xlabel('Tiempo [s]')            # axs[0].set_ylabel('Amplitud [V]')                # --- Histograma 1: intensidades ---            # axs[1].hist(intensidades, density=True, bins=30, histtype='barstacked', alpha=0.7, color='teal', edgecolor='gray')            # axs[1].set_xlabel('Intensidad del pico')            # axs[1].set_ylabel('Frecuencia')            # axs[1].set_yscale('log')            # axs[1].set_title('Distribución de intensidades')                    # Ajustar espacios entre gráficos            plt.tight_layout()            plt.show()    if Poisson:            fig, axs = plt.subplots(1, 1, figsize=(6, 3))                # --- (1,0) Histograma de cantidad de picos ---        numero_de_picos = np.array(numero_de_picos)                numero_de_picos=numero_de_picos[numero_de_picos<int(m_max)]                bins = np.arange(numero_de_picos.min(), numero_de_picos.max() + 2)                axs.hist(numero_de_picos, density=True, bins=bins,                color='darkcyan', edgecolor='slateblue', align='left')        #axs.set_title('Cantidad de picos por medición')        axs.set_xlabel('Cantidad de picos')        #axs.set_xlim(0,15)        axs.set_ylabel('Frecuencia')            mean=np.mean(numero_de_picos)        std=np.std(numero_de_picos)                print("Media:", f"{mean:.4f}")        print("Varianza:", f"{std**2:.4f}")        print("Var teórica B-E:", f"{mean**2 + mean:.4f}")        print("Factor Fano:",  f"{(std**2)/mean:.2f}")                # Ajustar distribución de subplots        plt.tight_layout()        plt.show()            return numero_de_picos#--------Test Kolmogorov-Smirnov------------#El estadístico es M, la máxima diferencia entre la F teórica y la "F" medidadef ecdf(data):    # Devuelve la función de probabilidad acumulada de mis datos, F_emp    # y también los xs, que son los datos donde se evaúa la F_emp    data = np.sort(data)    xs = np.unique(data)    F_emp = np.array([np.mean(data <= x) for x in xs])    return xs, F_empdef M(data, lam):    xs, F_medida = ecdf(data)    F_teorica = poisson.cdf(xs, lam)    return np.max(np.abs(F_medida - F_teorica))# función para generar la distribución de M# Dado el lambda obtenido por el MLE, lam_hatdef generate_M_distribution(lam_hat, n, B=5000, seed=None):    if seed is not None:        np.random.seed(seed)        M_sim = np.zeros(B)    for b in range(B):        sim = np.random.poisson(lam_hat, size=n)        M_sim[b] = M(sim, lam_hat)        return M_sim#calcula el M críticodef critical_value(M_sim, alpha=0.05):    # M_alpha tal que P(M >= M_alpha) = alpha    return np.quantile(M_sim, 1 - alpha)def kolmogorov_poisson_montecarlo(data, B=5000, seed=None, graficar = False):    if seed is not None:        np.random.seed(seed)        n = len(data)    lam_hat, lam_err = mle_lambda_from_data(numero_de_picos)        # --- Estadístico real ---    M_real = M(data, lam_hat)        # --- Monte Carlo ---    M_sim = np.zeros(B)    for b in range(B):        sim = np.random.poisson(lam_hat, size=n)        M_sim[b] = M(sim, lam_hat)            # Valor-p    p_value = np.mean(M_sim >= M_real)            M_crit = critical_value(M_sim, alpha=0.05)    #print("λ̂ =", lam_hat)    print(f"λ ={lam_hat:.2f} ± {lam_err:.2f}")    #print("M_real =", M_real)    #print("M_crit (α=0.05) =", M_crit)    p_value = np.mean(M_sim >= M_real) #(esto es equivalente a hacer la integral desde M_real hasta infinito)    print("p-valor", p_value)            if p_value > 0.05:        print("✔ No rechazo H0")    else:        print("❌ Rechazo H0")            if graficar:        fig, ax = plt.subplots(1, 1, figsize=(6, 3))        ax.hist(M_sim, density=True, bins= 'auto', histtype='barstacked', alpha=0.7, color='teal', edgecolor='gray')        ax.axvline(M_crit, linestyle="--", color = "darkviolet" , label = "M_crítico")        ax.axvline(M_real, linestyle="--", color = "firebrick", label = "M_medido")        ax.set_title('Distribución de M - H0 Verdadera')        ax.set_xlabel('Valor v.a.')        ax.set_ylabel('Densidad de probabilidad')        plt.legend()        plt.show()                    return M_real, p_value, lam_hat#-------------def Ajustar_poisson(numero_de_picos, info = False, test = False):            fig, axs = plt.subplots(1, 1, figsize=(6, 3))        #numero_de_picos=numero_de_picos[numero_de_picos<20]    bins = np.arange(numero_de_picos.min(), numero_de_picos.max() + 2)            #calculamos los errores de los bins    counts, bin_edges = np.histogram(numero_de_picos, bins=bins)        #Centros del bin y errores    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:]) -0.5    bin_err = np.sqrt(counts)        #como graficamos la densidad de probabilidad (va, es discreta pero se entiende), los normalizamos    density_counts = counts / (np.sum(counts) * np.diff(bin_edges))    errors_density = bin_err / (np.sum(counts) * np.diff(bin_edges))            #Graficar conteos en cada bin con barras de error    axs.errorbar(bin_centers, density_counts, yerr=errors_density,                 fmt='o', color='black', capsize=4, markersize=4)            axs.hist(numero_de_picos, density=True, bins=bins,            color='darkcyan', edgecolor='slateblue', align='left')    axs.set_xlabel('Cantidad de picos')    axs.set_ylabel('Frecuencia')                mean=np.mean(numero_de_picos)    std=np.std(numero_de_picos)        vals = numero_de_picos            #Esto caclula lambda con el MLE    lam, lam_err = mle_lambda_from_data(numero_de_picos)    #print(f"λ ={lam:.2f} ± {lam_err:.2f}")        # --- Curva de Poisson "continua" ---    #k_fine = np.linspace(vals.min(), vals.max(), 500)    #pmf_fine = poisson.pmf(np.round(k_fine), lam)        #axs.plot(k_fine, pmf_fine, 'r-', linewidth=2, label=f"λ ={lam:.2f} ± {lam_err:.2f}")            # --- Curva de Poisson discreta ---    k_vals = np.arange(vals.min(), vals.max()+1)    pmf_vals = poisson.pmf(k_vals, lam)    plt.plot(k_vals, pmf_vals, 'o--', color='mediumblue', label="Poisson λ MLE")        #plt.scatter(k_vals, pmf_vals, color='red', zorder=10, label=f"λ ={lam:.2f} ± {lam_err:.2f}")    #plt.plot(k_vals, pmf_vals, color='red', linestyle='--', alpha=0.5)                if test:        data = numero_de_picos        M_real, p_value, lam_hat = kolmogorov_poisson_montecarlo(data, B=5000, seed=None, graficar = False)                    if info:                if test==False:            print(f"λ ={lam:.2f} ± {lam_err:.2f}")                    print("Media:", mean)        print("Varianza:", f"{std**2:.4f}")        print("Var teórica B-E:", mean**2 + mean)        print("Factor Fano:",  f"{(std**2)/mean:.2f}")            axs.legend()    plt.tight_layout()    plt.show()    #%%Histograma y Ajustenumero_de_picos = analisis_rapido(n = 1001, ruta ='/Users/Mauri/Desktop/Labo 5/Conteo de fotones/theta = 180',          h = 0.002, dis = 7, pro = 0, i_graficado = 7, x_min = -4e-5, x_max = 4e-5,         graficar = False, Poisson = True)#%%Ajustar_poisson(numero_de_picos, test = False, info = True)#%% Test Kolmogorov-Smirnovdata = numero_de_picoslam_hat = np.mean(data)n =len(data) #1000M_real = M(data, lam_hat)M_sim = generate_M_distribution(lam_hat, n, B=5000, seed=None)M_crit = critical_value(M_sim, alpha=0.05)print("λ̂ =", lam_hat)print("M_real =", M_real)print("M_crit (α=0.05) =", M_crit)p_value = np.mean(M_sim >= M_real) #(esto es equivalente a hacer la integral desde M_real hasta infinito)print("p-valor", p_value)if M_real > M_crit:    print("❌ Rechazo H0")else:    print("✔ No rechazo H0")if p_value > 0.05:    print("✔ No rechazo H0")else:    print("❌ Rechazo H0")#%%M_real, p_value, lam_hat = kolmogorov_poisson_montecarlo(data, B=5000, seed=None, graficar = True)#%%#%%Ajuste y test para Bose-Einsteinnumero_de_picos = analisis_rapido(n = 1001, ruta ='/Users/Mauri/Desktop/Labo 5/Conteo de fotones/Bose-Einstein (r= 50Ohm)/Voltaje variable/v = 5V',          h = 0.004, dis = 7, pro = 0, i_graficado = 7, m_max = 10 ,         graficar = False, Poisson = True)#%%def Ajustar_Bose_Einstein(numero_de_picos, info = False, test = False):            fig, axs = plt.subplots(1, 1, figsize=(6, 3))        #numero_de_picos=numero_de_picos[numero_de_picos<20]    bins = np.arange(numero_de_picos.min(), numero_de_picos.max() + 2)            #calculamos los errores de los bins    counts, bin_edges = np.histogram(numero_de_picos, bins=bins)        #Centros del bin y errores    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:]) -0.5    bin_err = np.sqrt(counts)        #como graficamos la densidad de probabilidad (va, es discreta pero se entiende), los normalizamos    density_counts = counts / (np.sum(counts) * np.diff(bin_edges))    errors_density = bin_err / (np.sum(counts) * np.diff(bin_edges))            #Graficar conteos en cada bin con barras de error    axs.errorbar(bin_centers, density_counts, yerr=errors_density,                 fmt='o', color='black', capsize=4, markersize=4)            axs.hist(numero_de_picos, density=True, bins=bins,            color='darkcyan', edgecolor='slateblue', align='left')    axs.set_xlabel('Cantidad de picos')    axs.set_ylabel('Frecuencia')                    mean=np.mean(numero_de_picos)    std=np.std(numero_de_picos)            vals = numero_de_picos    n = len(numero_de_picos)            #Esto caclula eta con el MLE    k_bar = np.mean(vals)    eta_hat = 1 / k_bar        var_eta_hat = (1 + eta_hat) / (eta_hat**3 * n)    err_eta  = np.sqrt(var_eta_hat)    # --- Curva de Poisson "continua" ---    #k_fine = np.linspace(vals.min(), vals.max(), 500)    #pmf_fine = poisson.pmf(np.round(k_fine), lam)        #axs.plot(k_fine, pmf_fine, 'r-', linewidth=2, label=f"λ ={lam:.2f} ± {lam_err:.2f}")            # --- Curva de Bose-Einstein discreta ---    k_vals = np.arange(vals.min(), vals.max()+1)    # parámetro "p" para scipy    p_hat = 1 / (1 + eta_hat)    # pmf según scipy, ajustada para empezar en 0    pmf_vals = geom.pmf(k_vals, p_hat, loc=-1)        plt.plot(k_vals, pmf_vals, 'o--', color='mediumblue', label="B-E $\eta$ MLE")            #plt.scatter(k_vals, pmf_vals, color='red', zorder=10, label=f"λ ={lam:.2f} ± {lam_err:.2f}")    #plt.plot(k_vals, pmf_vals, color='red', linestyle='--', alpha=0.5)                if test:        data = numero_de_picos        M_real, p_value, lam_hat = kolmogorov_poisson_montecarlo(data, B=5000, seed=None, graficar = False)                    if info:                if test==False:            print(f"η ={eta_hat:.2f} ± {err_eta:.2f}")                    print("Media:", mean)        print("Varianza:", f"{std**2:.4f}")        print("Var teórica B-E:", mean**2 + mean)        print("Factor Fano:",  f"{(std**2)/mean:.2f}")            axs.legend()    plt.tight_layout()    plt.show()  #%%Ajustar_Bose_Einstein(numero_de_picos, info = True, test = False)